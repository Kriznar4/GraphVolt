{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjPHzK-4qBjG"
      },
      "source": [
        "## **Short Term Voltage Forecasting with Graph Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ikr0QdlqPCQ"
      },
      "source": [
        "By Karel Križnar, Anton Križnar, Vid Kališnik, Tomo Testen as part of the Stanford CS224W course project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y92Hum1SqXPW"
      },
      "source": [
        "This notebook accompanies our Medium post on [Short Term Voltage Forecasting with Graph Neural Networks](https://).\n",
        "The following code loads our database from Github and Drive and uses A3TGCN and GCONV-LSTM for short term voltage prediction.\n",
        "At the end, trained models are visualized.\n",
        "You also get to play with our best models.\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell.\n",
        "\n",
        "**Note**: You might need to use GPU for this Colab.\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation and setup\n",
        "Here we install and import some important libraries used for GNN."
      ],
      "metadata": {
        "id": "x9riUI9WvRGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6WgSaqStoXz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJp49A2yuAkd",
        "outputId": "7805169b-5308-4ea2-ece4-185c1c3951a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=3571339 sha256=d7f29946934b83d9f46a8917daecab666e0adc7498374011f1456fbaf817db33\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Building wheels for collected packages: torch-sparse\n"
          ]
        }
      ],
      "source": [
        "#This can take some time(even up to 25min)\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-geometric-temporal\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RArxIBuuy91p"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd '/content/'\n",
        "!git clone https://github.com/Kriznar4/GraphVolt.git\n",
        "%cd GraphVolt\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozq633RNUZmg"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "!pip install plotly\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import sys\n",
        "sys.path.append('/content/GraphVolt/src/utils')\n",
        "from utils import read_and_prepare_data, get_array_of_timestemps\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch_geometric import seed_everything\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric_temporal.nn.recurrent import A3TGCN, GConvLSTM\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0Tx6wJqQEYDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30Zpk5wuI3"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The network's data is used with SimpleGraphVoltDatasetLoader_Lazy. On initialization of our data loader object, all the preprocessing happens. Node features are put in a torch tensor sorted by date [oldest, …, newest], from which snapshots can be constructed."
      ],
      "metadata": {
        "id": "aOAjR6Paq4UA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNFythW4wtFm"
      },
      "outputs": [],
      "source": [
        "class SimpleGraphVoltDatasetLoader_Lazy(object):\n",
        "    \"\"\"\n",
        "    Check this https://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/torch_geometric_temporal/dataset/wikimath.html#WikiMathsDatasetLoader\n",
        "    for an example of how to implement a dataset loader\n",
        "\n",
        "    And here are the docs https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/signal.html\n",
        "    \"\"\"\n",
        "    def __init__(self, trafo_id, num_timesteps_in, num_timesteps_out, colab=False):\n",
        "        self._trafo_id = trafo_id\n",
        "        self._num_timesteps_in = num_timesteps_in\n",
        "        self._num_timesteps_out = num_timesteps_out\n",
        "        self.colab = colab\n",
        "        self._read_data()\n",
        "        self._get_edges_and_edge_weights_and_edge_features()\n",
        "        self._get_targets_and_features()\n",
        "\n",
        "    def _read_data(self):\n",
        "        dataset, self.mean_and_std = read_and_prepare_data(self._trafo_id, colab=self.colab) # save in self.mean_and_std\n",
        "        self._df_edges = dataset[\"edges_static_data\"]\n",
        "        self._df_measurments = dataset[\"measurements\"]\n",
        "        self._periods = len(self._df_measurments[\"date_time\"].unique())\n",
        "        self._node_counts = len(self._df_measurments[\"node_id\"].unique())\n",
        "\n",
        "    def _get_edges_and_edge_weights_and_edge_features(self):\n",
        "        self._edges = self._df_edges[[\"from_node_id\", \"to_node_id\"]].to_numpy().T\n",
        "        self._edge_features = self._df_edges.drop([\"from_node_id\", \"to_node_id\"], axis=1).to_numpy()\n",
        "        self.num_edge_features = self._edge_features.shape[1]\n",
        "\n",
        "    def _get_targets_and_features(self):\n",
        "        #voltage is the 0th column\n",
        "        #columns names: ['voltage', 'temperature_2m', 'snow_depth', 'cloud_cover', 'is_day',\n",
        "        #'shortwave_radiation', 'direct_radiation', 'diffuse_radiation',\n",
        "        #'direct_normal_irradiance', 'active_power', 'reactive_power', 'year',\n",
        "        #'month', 'day', 'hour', 'minute']\n",
        "\n",
        "        # voltage_index = 0\n",
        "        self.voltage_index = self._df_measurments.drop(columns=[\"date_time\", \"node_id\"]).columns.get_loc(\"voltage\") #TODO: is this ok\n",
        "\n",
        "        self._dfs = torch.Tensor(get_array_of_timestemps(self._df_measurments))#klobasa\n",
        "\n",
        "        self.num_features = self._dfs.shape[1]\n",
        "        self.num_snapshots = self._periods-self._num_timesteps_in-self._num_timesteps_out+1\n",
        "        self.snapshot_index = range(self.num_snapshots)\n",
        "\n",
        "    def get_snapshot(self, snapshot_i):\n",
        "        \"\"\"\n",
        "        Returns a snapshot at index snapshot_i of class Data from\n",
        "        pytorch geometric.\n",
        "        \"\"\"\n",
        "        #Data(x=[113, 21, 12], edge_index=[2, 114], edge_attr=[114, 5], y=[113, 4])\n",
        "\n",
        "        #voltage_index = 0\n",
        "\n",
        "        x = torch.Tensor(self._dfs[:,:,snapshot_i:snapshot_i+self._num_timesteps_in])\n",
        "        y = torch.Tensor(self._dfs[:, self.voltage_index, snapshot_i+self._num_timesteps_in:snapshot_i+self._num_timesteps_in+self._num_timesteps_out])\n",
        "        edge_index = torch.LongTensor(self._edges)\n",
        "        edge_attr = torch.Tensor(self._edge_features)\n",
        "\n",
        "        snapshot = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "        return snapshot\n",
        "\n",
        "    def temporal_signal_split_lazy(self, loader_data_index, train_ratio):\n",
        "        \"\"\"\n",
        "        Splits loader_data_index to two parts.\n",
        "        \"\"\"\n",
        "        split_index = int(train_ratio * len(loader_data_index))\n",
        "\n",
        "        train = loader_data_index[0:split_index]\n",
        "        test = loader_data_index[split_index:]\n",
        "\n",
        "        return train, test\n",
        "\n",
        "    def temporal_signal_split_lazy_cut(self,loader_data_index, offset=0, number_of_timestemps=2880):\n",
        "        \"\"\"\n",
        "        Gets the data from 'offset' to 'number_of_timestemps' from the data, and the same time period\n",
        "        just one year later for testing.\n",
        "        \"\"\"\n",
        "\n",
        "        timestemps_in_year = 365*24*60 // 15\n",
        "\n",
        "        #if we dont have enough data to test one year in advance\n",
        "        if offset + timestemps_in_year > len(loader_data_index):\n",
        "            raise ValueError(\"Offset is too big\")\n",
        "\n",
        "        train = loader_data_index[offset:offset+number_of_timestemps]\n",
        "        test = loader_data_index[offset + timestemps_in_year : offset + timestemps_in_year + number_of_timestemps]\n",
        "\n",
        "        return train, test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and split data"
      ],
      "metadata": {
        "id": "RntsbyPjsOiv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DutWzosg91D"
      },
      "outputs": [],
      "source": [
        "trafo_id = \"T1330\"\n",
        "num_timesteps_in = 12\n",
        "num_timesteps_out = 4\n",
        "test_ratio_vs_eval_ratio = 0.5\n",
        "\n",
        "manual_seed = 42\n",
        "seed_everything(manual_seed)\n",
        "\n",
        "print(\"Loading data...\")\n",
        "loader = SimpleGraphVoltDatasetLoader_Lazy(trafo_id, num_timesteps_in, num_timesteps_out, colab=True)\n",
        "print(\" done\")\n",
        "loader_data_index = loader.snapshot_index\n",
        "\n",
        "train_dataset, test_eval_dataset = loader.temporal_signal_split_lazy_cut(loader_data_index)\n",
        "eval_dataset, test_dataset = loader.temporal_signal_split_lazy(test_eval_dataset, train_ratio=test_ratio_vs_eval_ratio)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ],
      "metadata": {
        "id": "dCcFXemxvOB1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLgmZ0XRvtZy"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaH1QXynvsYb"
      },
      "outputs": [],
      "source": [
        "class GNN_A3TGCN(torch.nn.Module):\n",
        "    def __init__(self, node_features, periods, hidden=32):\n",
        "        super(GNN_A3TGCN, self).__init__()\n",
        "        self.name = \"GNN_A3TGCN\"\n",
        "        # Attention Temporal Graph Convolutional Cell\n",
        "        out_channels = hidden\n",
        "        self.tgnn = A3TGCN(in_channels=node_features,\n",
        "                           out_channels=out_channels,\n",
        "                           periods=periods)\n",
        "        # Equals single-shot prediction\n",
        "        self.linear = torch.nn.Linear(out_channels, periods)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        x = Node features for T time steps\n",
        "        edge_index = Graph edge indices\n",
        "        \"\"\"\n",
        "        h = self.tgnn(x, edge_index)\n",
        "        h = F.relu(h)\n",
        "        h = self.linear(h)\n",
        "        return h\n",
        "\n",
        "class GNN_GCNLSTM(torch.nn.Module):\n",
        "    def __init__(self,node_features, periods, hidden=32):\n",
        "        super(GNN_GCNLSTM, self).__init__()\n",
        "        self.name = \"GNN_GCNLSTM\"\n",
        "        out_channels= hidden\n",
        "        K = 5 # size of Chebyshev filter\n",
        "        self.recurrent_1 = GConvLSTM(\n",
        "            in_channels=node_features,\n",
        "            out_channels=out_channels,\n",
        "            K=K, normalization='sym',\n",
        "            bias=False)\n",
        "\n",
        "        self.linear = torch.nn.Linear(out_channels, periods)\n",
        "\n",
        "    def forward(self, timesteps, edge_index):\n",
        "        timesteps = timesteps.permute(2, 0, 1)\n",
        "        h1, c1 = None, None\n",
        "        for x in timesteps:\n",
        "            h1, c1 = self.recurrent_1(x, edge_index, H=h1, C=c1)\n",
        "\n",
        "        x = F.relu(h1)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train_eval"
      ],
      "metadata": {
        "id": "2XUlp-0PDqOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval(model, loader, device, train_dataset, eval_dataset, optimizer, loss_fn, scheduler=None, epochs=10, name=\"\"):\n",
        "    \"\"\"\n",
        "    Definition of the training loop.\n",
        "    \"\"\"\n",
        "    epoch_losses_train = []\n",
        "    epoch_losses_eval = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss_train = 0\n",
        "\n",
        "        for snapshot_i in tqdm(train_dataset, desc=\"Training epoch {}\".format(epoch)):\n",
        "            snapshot = loader.get_snapshot(snapshot_i)\n",
        "            snapshot.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            out = model(snapshot.x, snapshot.edge_index)\n",
        "            loss = loss_fn()(out, snapshot.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss_train += loss.detach().cpu().numpy()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(epoch_loss_train)\n",
        "\n",
        "        epoch_losses_train.append(epoch_loss_train)\n",
        "\n",
        "        model.eval()\n",
        "        epoch_loss_eval = 0\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for snapshot_j in tqdm(eval_dataset, desc=\"Evaluating epoch {}\".format(epoch)):\n",
        "                snapshot = loader.get_snapshot(snapshot_j)\n",
        "                snapshot.to(device)\n",
        "\n",
        "                out = model(snapshot.x, snapshot.edge_index)\n",
        "\n",
        "                loss = loss_fn()(out, snapshot.y).cpu().numpy()\n",
        "                epoch_loss_eval += loss\n",
        "\n",
        "            epoch_losses_eval.append(epoch_loss_eval)\n",
        "            if min(epoch_losses_eval) == epoch_loss_eval:\n",
        "                torch.save(model.state_dict(), name)\n",
        "            print(\"Epoch: {}, Train Loss: {:.7f}, Eval Loss: {:.7f}\".format(epoch, epoch_loss_train, epoch_loss_eval))\n",
        "\n",
        "\n",
        "    return epoch_losses_train, epoch_losses_eval"
      ],
      "metadata": {
        "id": "9jcpDdzmCSLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval"
      ],
      "metadata": {
        "id": "pZIQWbsDSyQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, loader, test_dataset, device, loss_fn, std, mean):\n",
        "    preds = []\n",
        "    ys = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        loss_all = 0\n",
        "        loss_elementwise = 0\n",
        "\n",
        "        for snapshot_j in tqdm(test_dataset, desc=\"Evaluating\"):\n",
        "            snapshot = loader.get_snapshot(snapshot_j)\n",
        "            snapshot = snapshot.to(device)\n",
        "\n",
        "            out= model(snapshot.x, snapshot.edge_index)\n",
        "\n",
        "            loss_all += loss_fn()(out, snapshot.y).cpu().numpy()\n",
        "            loss_elementwise += loss_fn(reduction=\"none\")(out, snapshot.y).cpu().numpy()\n",
        "\n",
        "            ys.append(snapshot.y.cpu().numpy()*std+mean)\n",
        "            preds.append(out.cpu().numpy()*std+mean)\n",
        "\n",
        "        loss_all *= std/len(test_dataset)\n",
        "        loss_elementwise *= std/len(test_dataset)\n",
        "\n",
        "        ys = np.stack(ys, axis=-1)\n",
        "        preds = np.stack(preds, axis=-1)\n",
        "    return loss_all, loss_elementwise, preds, ys"
      ],
      "metadata": {
        "id": "2TPDsd0FSxeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the models"
      ],
      "metadata": {
        "id": "NY0UmVfiMkxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHOOSE YOUR MODEL HERE**"
      ],
      "metadata": {
        "id": "aejQEq0sPjxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose: 'A3TGCN' or 'GCN-LSTM'\n",
        "model_type = 'GCN-LSTM'"
      ],
      "metadata": {
        "id": "BzEgISADV10w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the model:"
      ],
      "metadata": {
        "id": "quQKMxmuYOcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "device_str = 'cuda'\n",
        "hidden = 64\n",
        "learning_rate = 0.01\n",
        "\n",
        "device = torch.device(device_str)\n",
        "seed_everything(manual_seed)\n",
        "if model_type == 'A3TGCN':\n",
        "  model = GNN_A3TGCN(node_features=loader.num_features, periods=num_timesteps_out, hidden=hidden).to(device)\n",
        "elif model_type == 'GCN-LSTM':\n",
        "  model = GNN_GCNLSTM(node_features=loader.num_features, periods=num_timesteps_out, hidden=hidden).to(device)\n",
        "else:\n",
        "  print(\"Wrong model name\")\n",
        "\n",
        "#get dateime string of now\n",
        "now = pd.Timestamp.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "name = f\"/content/GraphVolt/models/final{model.name}_{now}_{trafo_id}_epochs-{epochs}_in-{num_timesteps_in}_out-{num_timesteps_out}_train-ratio-1month_lr-{learning_rate}_hidden-{hidden}.pt\"\n",
        "name_txt = f\"/content/GraphVolt/models/final{model.name}_{now}_{trafo_id}_epochs-{epochs}_in-{num_timesteps_in}_out-{num_timesteps_out}_train-ratio-1month_lr-{learning_rate}_hidden-{hidden}.txt\"\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = torch.nn.MSELoss\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "losses_train, losses_eval = train_eval(model, loader, device, train_dataset, eval_dataset, optimizer, loss_fn, scheduler=scheduler, epochs=epochs, name=name)"
      ],
      "metadata": {
        "id": "94A-mx6KMsdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std = loader.mean_and_std[\"measurements\"][1][\"voltage\"]\n",
        "mean = loader.mean_and_std[\"measurements\"][0][\"voltage\"]"
      ],
      "metadata": {
        "id": "ex0CCHanZNWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(name))"
      ],
      "metadata": {
        "id": "qvrkpnWBZOS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.L1Loss"
      ],
      "metadata": {
        "id": "CWjdb06hZcuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test, loss_test_elementwise, preds, ys = eval(model, loader, test_dataset, device, loss_fn, std, mean)\n",
        "loss_test_timewise = loss_test_elementwise.mean(axis=0)\n",
        "print(\"Loss all: {:.7f}\".format(loss_test))\n",
        "print(\"Loss elementwise: {}\".format(loss_test_elementwise))"
      ],
      "metadata": {
        "id": "R8qAU0DcZg84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node = 50\n",
        "pred_ind = 0\n",
        "\n",
        "start = 0\n",
        "len_measurements = 1400\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(ys[node,pred_ind,start:start+len_measurements], label=\"y\")\n",
        "plt.plot(preds[node,pred_ind,start:start+len_measurements], label=\"pred\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "1dcdN4TGlafe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create txt file at name_txt\n",
        "with open(name_txt, \"w\") as f:\n",
        "    #print losses\n",
        "    f.write(\"train losses:\\n\")\n",
        "    f.write(str(losses_train))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"eval losses:\\n\")\n",
        "    f.write(str(losses_eval))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"test loss:\\n\")\n",
        "    f.write(str(loss_test))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(str(loss_test_timewise))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(str(loss_test_elementwise))\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "aT_92ooalb1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}